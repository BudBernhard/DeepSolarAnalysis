{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "## for correlation matrices\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "## for linear models\n",
    "import statsmodels.api as sm\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from yellowbrick.classifier import ConfusionMatrix\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Must download from http://web.stanford.edu/group/deepsolar/deepsolar_tract.csv and delete the first \",\"\n",
    "df = pd.read_csv(\"deepsolar_tract.csv\", encoding = \"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all deepsolar inputs\n",
    "\n",
    "df = df.drop(columns=['solar_system_count'], axis = 1)\n",
    "df = df.drop(columns=['total_panel_area'], axis = 1)\n",
    "df = df.drop(columns=['solar_panel_area_per_capita'], axis =1)\n",
    "\n",
    "df = df.drop(columns=['solar_panel_area_divided_by_area'], axis = 1)\n",
    "df = df.drop(columns=['tile_count_residential'], axis = 1)\n",
    "df = df.drop(columns=['tile_count_nonresidential'], axis = 1)\n",
    "df = df.drop(columns=['solar_system_count_residential'], axis =1)\n",
    "\n",
    "df = df.drop(columns=['solar_system_count_nonresidential'], axis = 1)\n",
    "df = df.drop(columns=['total_panel_area_residential'], axis = 1)\n",
    "df = df.drop(columns=['total_panel_area_nonresidential'], axis = 1)\n",
    "df = df.drop(columns=['number_of_solar_system_per_household'], axis =1)\n",
    "\n",
    "# Remove all unique identifiers, objects, and booleans\n",
    "df = df.drop(columns=['county',\n",
    "                      'state',\n",
    "                     'electricity_price_transportation',\n",
    "                     'voting_2016_dem_win',\n",
    "                     'voting_2012_dem_win',\n",
    "                     'fips'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tilesLargerThanZero = range(1,4469)\n",
    "df['has_tiles'] = (df.tile_count > 0).mul(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('tile_count', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    31209\n",
      "0    31209\n",
      "Name: has_tiles, dtype: int64 \n",
      "\n",
      " 1    10392\n",
      "0     3133\n",
      "Name: has_tiles, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Define X and y\n",
    "y = df['has_tiles']\n",
    "X = df.drop('has_tiles', axis = 1)\n",
    "# Split the data into training and test sets\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "#ADD STRATIFIED HERE\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=17)\n",
    "#print(y_train.value_counts(),'\\n\\n', y_test.value_counts())\n",
    "\n",
    "# SMOTE\n",
    "smt = SMOTE()\n",
    "X_train, y_train = smt.fit_sample(X_train, y_train)\n",
    "print(y_train.value_counts(),'\\n\\n', y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# col_names = list(df.columns)\n",
    "# scaler = preprocessing.MinMaxScaler()\n",
    "# Xtrain = scaler.fit_transform(X_train)\n",
    "# Xtest = scaler.transform(X_test)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train.fillna(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=LogisticRegression(C=0.0002, class_weight=None,\n",
       "                                             dual=False, fit_intercept=True,\n",
       "                                             intercept_scaling=1, l1_ratio=None,\n",
       "                                             max_iter=100, multi_class='auto',\n",
       "                                             n_jobs=None, penalty='l1',\n",
       "                                             random_state=None, solver='saga',\n",
       "                                             tol=0.0001, verbose=0,\n",
       "                                             warm_start=False),\n",
       "                max_features=None, norm_order=1, prefit=False, threshold=None)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel_ = SelectFromModel(LogisticRegression(C=.0002, solver = 'saga', penalty='l1'))\n",
    "sel_.fit(scaler.transform(X_train.fillna(0)), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total features: 150\n",
      "selected features: 8\n",
      "features with coefficients shrank to zero: 142\n"
     ]
    }
   ],
   "source": [
    "selected_feat = X_train.columns[(sel_.get_support())]\n",
    "print('total features: {}'.format((X_train.shape[1])))\n",
    "print('selected features: {}'.format(len(selected_feat)))\n",
    "print('features with coefficients shrank to zero: {}'.format(\n",
    "      np.sum(sel_.estimator_.coef_ == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['education_bachelor', 'employed', 'education_high_school_graduate_rate',\n",
       "       'heating_fuel_coal_coke_rate', 'relative_humidity',\n",
       "       'occupancy_vacant_rate', 'mortgage_with_rate',\n",
       "       'incentive_count_residential'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remaining_feats = X_train.columns[(sel_.estimator_.coef_ != 0).ravel().tolist()]\n",
    "remaining_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
