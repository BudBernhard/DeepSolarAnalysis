{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying Potential for Solar Investment from Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contributors: Buddy Bernhard, Allison Lee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. <a href=#summary>Summary</a>\n",
    "2. <a href=#data>Data Source</a>\n",
    "3. <a href=#analysis>Analytical Approach</a>\n",
    "4. <a href=#findings>Model Findings</a>\n",
    "5. <a href=#next>Next Steps</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=summary></a>\n",
    "### Summary\n",
    "\n",
    "Can we predict where there's potential for solar investment in the contiguous U.S.? <br>\n",
    "\n",
    "The DeepSolar project is a deep learning framework that analyzes satellite imagery to identify the GPS locations and sizes of solar photovoltaic (PV) panels. DeepSolar was developed within Stanford's [Magic Lab](https://magiclab.stanford.edu/) and [Sustainable Systems Lab](https://magiclab.stanford.edu/). Our project aims to utilize that data to pinpoint areas where a) solar infrastructure is underdeveloped and conditions appear to be conducive, and b) there are opportunity zones for investment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=data></a>\n",
    "### Data Source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DeepSolar dataset is a rich dataset consisting of 72537 observations, each of which represent one census tract in the continguous U.S. The dataset has 151 features, which include attributes such as racial makeup, electricity prices for different sectors (residential, industrial, commercial, etc), education levels, and environmental attributes such as relative humidity, wind speed, and daily solar radiation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [DeepSolar database (census tract level)](http://web.stanford.edu/group/deepsolar/deepsolar_tract.csv)\n",
    "* [DeepSolar database metadata](http://web.stanford.edu/group/deepsolar/deepsolar_tract_meta.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=analysis></a>\n",
    "### Analytical Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After removing redundant features and missing values, our dataset consisted of roughly 55,000 tracts and 131 features. We created our 'target' column named 'has_tiles'. This column represents the outcome we are trying to predict with our model. If the DeepSolar dataset indicated that the tract had solar tiles (no matter the number), this column was coded as 1. If not, the column was coded as 0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One challenge we faced was that roughly 4 out of every 5 tracts had solar panels. This imbalance in our data means that our model could potentially learn to predict that a tract has panels more often, simply because there are more tracts with panels in our dataset. To combat this challenge, we tried three different sampling methods to 'balance' these two categories. The methods were: oversampling from the tracts that don't have panels, undersampling from the tracts that do have panels, and generating synthetic data via a method called SMOTE. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then tested and compared the performance of four different classifier models with different combinations of sampling methods and hyperparameter tuning. The models that we tested were: Decision Trees, Random Forests, K-Nearest Neighbors, and Logistic Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=findings></a>\n",
    "### Model Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table below summarizes the metrics of each model combination on our test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/model_comparison.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to optimize our model based off of accuracy score (when we used sampling methods), and balanced accuracy score when we did not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Insert AUC-ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=next></a>\n",
    "### Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
